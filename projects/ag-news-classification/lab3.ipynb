{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405d38f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4727a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "all_lemmas = []\n",
    "for train_idx in ['1', '2', '3', '4']:\n",
    "    c = pd.read_csv(f\"../assets/annotated-corpus/train/{train_idx}.tsv\",delimiter='\\t')\n",
    "    sentence_lemmas=[]\n",
    "    prev_doc_id = c.values[0][0]\n",
    "    for el in  tqdm(c.values):\n",
    "        lemma = el[3]\n",
    "        if el[1]==\"<endofsentence>\":\n",
    "            continue\n",
    "        if el[0]!=prev_doc_id:\n",
    "            all_lemmas.append((prev_doc_id, sentence_lemmas))\n",
    "            sentence_lemmas=[]\n",
    "            prev_doc_id=el[0]\n",
    "        else:\n",
    "            if type(lemma) == str:\n",
    "                lemma_filtered = re.sub(r'[^\\w\\s]','', lemma)\n",
    "                if len(lemma_filtered)==0 or lemma_filtered in stops:\n",
    "                    continue\n",
    "                sentence_lemmas.append(lemma_filtered.lower())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e73ef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(all_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f74d2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [el for sentence in all_lemmas for el in sentence[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c78d093",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46da3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "word_cnt = Counter(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b6563",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1ce74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.percentile(list(word_cnt.values()), 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c852a604",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Counter({k: c for k, c in word_cnt.items() if c >=13}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224f50b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cnt = Counter({k: c for k, c in word_cnt.most_common(8192)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0664b26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d438e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"tokens_freq.json\", \"w\") as file:\n",
    "    json.dump(list(word_cnt.items()), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_term_document_matrix(documents, token_freq):\n",
    "    matrix = []\n",
    "    token_freq = list(token_freq.keys())\n",
    "    for doc in tqdm(documents):\n",
    "        tokens = doc[1]\n",
    "        tokens_cnt = Counter(tokens)\n",
    "        row = [tokens_cnt[token.lower()] for token in token_freq]\n",
    "        matrix.append(row)\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648f3166",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51b894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_doc_matrix = create_term_document_matrix(all_lemmas,word_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f984bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"term_document_matrix.json\", \"w\") as file:\n",
    "    json.dump(term_doc_matrix, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084ba58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2b325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_doc_matrix = np.array(term_doc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42c7cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_doc_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a4c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(dpi=500)\n",
    "plt.imshow(np.asarray(term_doc_matrix[:512]), interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c880289",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero([[1,1,0,0],\n",
    "                  [0,1,1,0]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43da3121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "IDF = {}\n",
    "terms = list(word_cnt.keys())\n",
    "for i in tqdm(range(len(terms))):\n",
    "    IDF[i] = log( (1+N) / (1+np.count_nonzero(term_doc_matrix[:,i]) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a72de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_doc_matrix[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed808c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf_idf(term_document_matrix, terms):\n",
    "    tf_idf_matrix = []\n",
    "    for document in tqdm(term_document_matrix):\n",
    "        tf_idf_row=[]\n",
    "        for i in range(len(terms)):\n",
    "            tf = document[i]\n",
    "            tf_idf_row.append(tf * IDF[i])\n",
    "        tf_idf_matrix.append(tf_idf_row)\n",
    "\n",
    "    return tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb627a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix = compute_tf_idf(term_doc_matrix[:10000], terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d544a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix_np = np.array(tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff5cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd91856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.figure(dpi=1000)\n",
    "plt.imshow(np.asarray(tf_idf_matrix[:10]), interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c98cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = tf_idf_matrix[0]\n",
    "print(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef5189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences=[el[1] for el in all_lemmas[:]], vector_size=256, window=5, min_count=1, workers=14)\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7c1e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faefa1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lemmas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88599611",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train([el[1] for el in all_lemmas[:]], total_examples=len(all_lemmas[:]), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90abf545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "1 - distance.cosine(model.wv[\"winter\"], model.wv[\"summer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4f3749",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(model.wv[\"winter\"], model.wv[\"summer\"])/(np.linalg.norm(model.wv[\"winter\"])*np.linalg.norm(model.wv[\"summer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0135e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def cosine_similarity(v1,v2):\n",
    "    dot_product, norm1, norm2 = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]\n",
    "        y = v2[i]\n",
    "        dot_product+=x*y\n",
    "        norm1 += x*x\n",
    "        norm2 += y*y\n",
    "    norm1 = math.sqrt(norm1)\n",
    "    norm2 = math.sqrt(norm2)\n",
    "    return dot_product/(norm1*norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d5fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(model.wv[\"winter\"], model.wv[\"summer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3321c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "words = list(model.wv.key_to_index)\n",
    "X = [model.wv[word] for i, word in enumerate(words)]\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727c0749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb454b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca1 = PCA(n_components=512)\n",
    "tf_idf_matrix_np_transformed = pca1.fit_transform(tf_idf_matrix_np.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2250369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "words = list(model.wv.key_to_index)\n",
    "X = [model.wv[word] for i, word in enumerate(words)]\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab0ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in ['winter',\"snow\",\"summer\",\"hot\",\"cold\",\"bomb\",\"president\",\"cool\",\"heat\",\"sunday\",\"december\",\"july\"]:\n",
    "    vec = model.wv[word]\n",
    "    x,y = pca.transform(vec.reshape(1, -1))[0][0], pca.transform(vec.reshape(1, -1))[0][1]\n",
    "    plt.plot(x,y, 'o', color='red')\n",
    "    plt.annotate(word, (x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa060ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in ['president', 'election',\"government\",\"senate\",\"monday\", 'december']:\n",
    "    vec = model.wv[word]\n",
    "    x,y = pca.transform(vec.reshape(1, -1))[0][0], pca.transform(vec.reshape(1, -1))[0][1]\n",
    "    plt.plot(x,y, 'o', color='red')\n",
    "    plt.annotate(word, (x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ad5362",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "def get_sentence_emb(sent):\n",
    "    sum_vector = np.zeros(256)\n",
    "    for token in sent:\n",
    "        try:\n",
    "            emb = model.wv[token]\n",
    "        except:\n",
    "            continue\n",
    "        sum_vector += emb\n",
    "    return sum_vector/len(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8c7e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentence_emb(all_lemmas[6][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b7a3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix_np = np.array(tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13ed303",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix_np tf_idf_matrix_np_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87edeac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723f705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(tf_idf_matrix_np_transformed[list(word_cnt.keys()).index(\"election\"),:], tf_idf_matrix_np_transformed[list(word_cnt.keys()).index(\"president\"),:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7115dc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(tf_idf_matrix_np[:,list(word_cnt.keys()).index(\"election\")], tf_idf_matrix_np[:,list(word_cnt.keys()).index(\"president\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c456eeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(model.wv[\"election\"], model.wv[\"president\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8685b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedd_csv_text(lemmas,test_idx):\n",
    "    for el in lemmas:\n",
    "        docid=el[0]\n",
    "        text=el[1]\n",
    "        with open(f\"../assets/annotated-corpus/test/{test_idx}_emb.tsv\", \"a\", encoding=\"utf-8\") as file:\n",
    "            embed = get_sentence_emb(text)\n",
    "            file.write(f\"{docid}\\t\")     \n",
    "            for emb in embed:\n",
    "                file.write(f\"{emb}\\t\")\n",
    "            file.write(\"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fd64f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "for the_idx in ['1', '2', '3', '4']:\n",
    "    test_all_lemmas = []\n",
    "    c = pd.read_csv(f\"../assets/annotated-corpus/test/{the_idx}.tsv\",delimiter='\\t')\n",
    "    sentence_lemmas=[]\n",
    "    prev_doc_id = c.values[0][0]\n",
    "    for el in  tqdm(c.values):\n",
    "        lemma = el[3]\n",
    "        if el[1]==\"<endofsentence>\":\n",
    "            continue\n",
    "        if el[0]!=prev_doc_id:\n",
    "            test_all_lemmas.append((prev_doc_id, sentence_lemmas))\n",
    "            sentence_lemmas=[]\n",
    "            prev_doc_id=el[0]\n",
    "        else:\n",
    "            if type(lemma) == str:\n",
    "                lemma_filtered = re.sub(r'[^\\w\\s]','', lemma)\n",
    "                if len(lemma_filtered)==0 or lemma_filtered in stops:\n",
    "                    continue\n",
    "                sentence_lemmas.append(lemma_filtered.lower())\n",
    "    embedd_csv_text(test_all_lemmas,the_idx)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe1854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_all_lemmas)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5a46ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
