{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec8ac1f-5a9c-4930-9915-4e95f227af80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46733adb-c85c-4d83-b350-51f02f86c0bd",
   "metadata": {},
   "source": [
    "# Пункт 1 и 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9697f9-740b-4921-a72d-f5c16385c63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../assets/annotated-corpus/test-embeddings.tsv\", sep=\"\\t\", header=None, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a825dcc4-3036-4139-9912-7437a99835d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2ac76c-8400-4ed8-8139-b883d03a8b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target\"] = df[0].str.rsplit(\"_\", n=1, expand=True)[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bece79-ce0b-47cb-8410-3167f8716036",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df[\"target_enc\"] = label_encoder.fit_transform(df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54a2410-0b92-4356-9245-963ced65b74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"target\", \"target_enc\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c02d29e-c302-49bd-9998-787b7a5d9450",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target\"].unique(), df[\"target_enc\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c80748-bb96-4505-9977-094770de1cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae842f1b-7219-403e-95ce-137897221dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(true, pred):\n",
    "    classes = set(true + pred)\n",
    "    num_classes = len(classes)\n",
    "    mat = np.zeros((num_classes, num_classes))\n",
    "    n = max(len(true), len(pred))\n",
    "    for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "            for k in range(n):\n",
    "                if true[k] == i:\n",
    "                    if pred[k] == j:\n",
    "                        mat[i][j] = mat[i][j] + 1\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8009332a-8f1a-4b4b-b3ba-1c1087d63af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_recall_fscore_accuracy(cm, beta=1.0):\n",
    "    true_pos = np.diag(cm)\n",
    "    false_pos = np.sum(cm, axis=0) - true_pos\n",
    "    false_neg = np.sum(cm, axis=1) - true_pos\n",
    "    \n",
    "    precision = true_pos / (true_pos + false_pos)\n",
    "    recall = true_pos / (true_pos + false_neg)\n",
    "\n",
    "    numerator = (1 + math.pow(beta, 2)) * recall * precision\n",
    "    denominator = (math.pow(beta, 2) * precision) + recall\n",
    "\n",
    "    fscore = numerator / denominator\n",
    "\n",
    "    accuracy = true_pos / np.sum(cm, axis=1)\n",
    "\n",
    "    return precision, recall, fscore, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd8637-edac-484d-a623-006bcf1221f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_precision(matrix_df, level = 'micro'):\n",
    "    arr = matrix_df.to_numpy() # Total Number of Instance\n",
    "\n",
    "    rows = np.sum(arr, axis = 1) # Sum of rows of each class (TP(i) + FN(i))\n",
    "    columns = np.sum(arr, axis = 0) # Sum of columns of each class (TP(i) + FP(i))\n",
    "\n",
    "    diagonals = np.diag(arr) # Get the diagonals \n",
    "\n",
    "    if (level == 'micro'):\n",
    "        # sum of TP(i) / sum of (TP(i) + FN(i))\n",
    "        recall = sum(diagonals) * 100 / sum(rows)\n",
    "        # sum of TP(i) / sum of (TP(i) + FP(i))\n",
    "        precision = sum(diagonals) * 100 / sum(columns)\n",
    "    elif (level == 'macro'):\n",
    "        # sum of recall(i) / c\n",
    "        recall = sum((diagonals / rows)) * 100 / len(diagonals)\n",
    "        # sum of precision(i) / c\n",
    "        precision = sum((diagonals / columns)) * 100 / len(diagonals)\n",
    "    elif (level == 'weighted'):\n",
    "        # sum of recall(i) * true proportion of the class\n",
    "        recall = sum((diagonals / rows) * (rows / np.sum(arr))) * 100\n",
    "        # sum of precision(i) * true proportion of the class\n",
    "        precision = sum((diagonals / columns) * (rows / np.sum(arr))) * 100\n",
    "\n",
    "    return recall, precision\n",
    "\n",
    "\n",
    "def compute_f_score(recall, precision, beta = 1.0):\n",
    "    numerator = (1 + math.pow(beta, 2)) * recall * precision\n",
    "    denominator = (math.pow(beta, 2) * precision) + recall\n",
    "\n",
    "    return numerator/denominator\n",
    "\n",
    "\n",
    "def compute_accuracy(matrix_df, predictions):\n",
    "    accuracy = matrix_df.to_numpy().trace() * 100 / len(predictions)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def get_precision_recall_fscore_accuracy_v2(cm, level=\"macro\", beta=1.0):\n",
    "    recall, precision = recall_precision(cm, level)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c121be-6407-4a8f-82fa-44ec04598f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f814fcfc-3941-44fa-b644-8a44693a53e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    { \n",
    "        \"kernel\": [\"linear\"],\n",
    "        \"C\": [0.75, 1.0, 1.25],\n",
    "        \"gamma\": [\"scale\", \"auto\"]\n",
    "    },\n",
    "    { \n",
    "        \"kernel\": [\"poly\"],\n",
    "        \"degree\": [3],\n",
    "        \"C\": [1.0, 1.25, 1.5],\n",
    "        \"gamma\": [\"scale\", \"auto\"]\n",
    "        # \"class_weight\": [None, \"balanced\"]\n",
    "    },\n",
    "    {\n",
    "        \"kernel\": [\"rbf\"],\n",
    "        \"C\": [1.0, 1.25, 1.5],\n",
    "        \"gamma\": [\"scale\", \"auto\"]\n",
    "        # \"class_weight\": [None, \"balanced\"]\n",
    "    },\n",
    "    {\n",
    "        \"kernel\": [\"sigmoid\"],\n",
    "        \"C\": [0.5, 0.75, 1.0],\n",
    "        \"gamma\": [\"scale\", \"auto\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "param_grid = ParameterGrid(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e846c064-a094-4fe3-a875-2261adc278ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns.difference([0, 'target', 'target_enc'])]\n",
    "y = df[\"target_enc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5fdc65-6c0c-44fa-8ef1-67a31b642d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"accuracy\": dict(),\n",
    "    \"precision\": dict(),\n",
    "    \"recall\": dict(),\n",
    "    \"fscore\" : dict(),\n",
    "    \"exec_time\": dict()\n",
    "}\n",
    "\n",
    "metrics_names = [\"accuracy\", \"precision\", \"recall\", \"fscore\", \"exec_time\"]\n",
    "for i, param in tqdm(enumerate(param_grid)):\n",
    "    clf = SVC(**param)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    clf.fit(X, y)\n",
    "    exec_time = time.time() - start_time\n",
    "    \n",
    "    y_pred = clf.predict(X)\n",
    "\n",
    "    cm = confusion_matrix(y.tolist(), y_pred.tolist())\n",
    "    pr, rec, fscore, acc = get_precision_recall_fscore_accuracy(cm)\n",
    "\n",
    "    print(f\"Model version №{i + 1}\")\n",
    "    print(\"params\", param)\n",
    "    for metr, name in zip([acc, pr, rec, fscore, exec_time], metrics_names):\n",
    "        metrics[name][f\"model_{i + 1}\"] = metr\n",
    "        print(name, np.mean(metr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36e893c-cb5f-493e-abf5-d07c34bc3d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(X, y, param_grid):\n",
    "    metrics = {\n",
    "        \"accuracy\": dict(),\n",
    "        \"precision\": dict(),\n",
    "        \"recall\": dict(),\n",
    "        \"fscore\" : dict(),\n",
    "        \"exec_time\": dict()\n",
    "    }\n",
    "\n",
    "    model_params = dict()\n",
    "    \n",
    "    metrics_names = [\"accuracy\", \"precision\", \"recall\", \"fscore\", \"exec_time\"]\n",
    "    for i, param in tqdm(enumerate(param_grid)):\n",
    "        clf = SVC(**param)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        clf.fit(X, y)\n",
    "        exec_time = time.time() - start_time\n",
    "        \n",
    "        y_pred = clf.predict(X)\n",
    "    \n",
    "        cm = confusion_matrix(y.tolist(), y_pred.tolist())\n",
    "        pr, rec, fscore, acc = get_precision_recall_fscore_accuracy(cm)\n",
    "    \n",
    "        print(f\"Model version №{i + 1}\")\n",
    "        print(\"params\", param)\n",
    "        for metr, name in zip([acc, pr, rec, fscore, exec_time], metrics_names):\n",
    "            metrics[name][f\"model_{i + 1}\"] = metr\n",
    "            print(name, np.mean(metr))\n",
    "\n",
    "        model_params[f\"model_{i + 1}\"] = param\n",
    "\n",
    "    return metrics, model_params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8d6f61-8a38-4183-94b7-db182ed78cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model_by_metrics(metric_model, metrics_names):\n",
    "    for name in metrics_names:\n",
    "        k, v = max(metric_model[name].items(), key=lambda x: np.mean(x[1]))\n",
    "        print(f\"Metric {name}: model {k} with mean value {np.mean(v)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e5bb58-fdb2-441b-91a5-5098379b0e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_1, model_params_1 = grid_search(X, y, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4980b93-3b5c-4713-b895-43e612bdd432",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_model_by_metrics(metrics_1, [\"accuracy\", \"precision\", \"recall\", \"fscore\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71775e03-1f69-459b-bd26-28603e6e9c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_metrics = { metric_name: val for metric_name, d in metrics.items() for model_name, val in d.items() if model_name == \"model_17\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055a6e6d-2f0c-4223-a5c1-a7160cc84e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f0a40a-d917-45a2-929d-59898158585d",
   "metadata": {},
   "source": [
    "# Пункт 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2e64ad-16fd-4a49-8f07-403738e14065",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_log = X.copy().apply(np.log).fillna(0.0)\n",
    "X_sin = X.copy().apply(np.sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc95387-9a24-4303-9533-8e3fadaf3d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_names = [\"accuracy\", \"precision\", \"recall\", \"fscore\", \"exec_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ad56b9-6c34-467a-bcc6-a7b0c4ed8edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(X, y, model_params):\n",
    "    clf = SVC(**model_params_1[\"model_17\"])\n",
    "    start_time = time.time()\n",
    "    clf.fit(X, y)\n",
    "    exec_time = time.time() - start_time\n",
    "    \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y.tolist(), y_pred.tolist())\n",
    "    pr, rec, fscore, acc = get_precision_recall_fscore_accuracy(cm)\n",
    "    \n",
    "    metrics = dict()\n",
    "    for metr, name in zip([acc, pr, rec, fscore, exec_time], metrics_names):\n",
    "        metrics[name] = metr\n",
    "        print(name, np.mean(metr))\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa34720-5821-4496-bb9a-22ca6fb590f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model_metrics = fit_predict(X_log, y, model_params_1[\"model_17\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd992d1-07fe-445a-847a-5ed7b0afba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sin_model_metrics = fit_predict(X_sin, y, model_params_1[\"model_17\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
