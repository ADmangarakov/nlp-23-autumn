{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a9a4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Пустой список для хранения списков лемм\n",
    "all_lemmas = []\n",
    "\n",
    "# Перебираем папки\n",
    "for folder in ['1', '2', '3', '4']:\n",
    "    # Путь к папке\n",
    "    folder_path = os.path.join('assets/annotated_corpus/test/', folder)\n",
    "    # Перебираем файлы в папке\n",
    "    for file in os.listdir(folder_path):\n",
    "        # Если это tsv файл\n",
    "        if file.endswith('.tsv') and file.startswith('annotation'):\n",
    "            # Путь к файлу\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            # Читаем файл\n",
    "            df = pd.read_csv(file_path, sep='\\t', header=None)\n",
    "            # Группируем леммы по предложениям (предполагает, что предложение отделено пустой строкой)\n",
    "            lemma_list = df[2].tolist()\n",
    "            sentence_lemmas = []\n",
    "            for lemma in lemma_list:\n",
    "                if str(lemma) != 'nan':\n",
    "                    sentence_lemmas.append(lemma)\n",
    "                else:\n",
    "                    all_lemmas.append(sentence_lemmas)\n",
    "                    sentence_lemmas = []\n",
    "\n",
    "            if len(sentence_lemmas) > 0:\n",
    "                all_lemmas.append(sentence_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8155f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b8381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "data_no_stopwords = [[word for word in sentence if word not in stop_words] for sentence in all_lemmas]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ce403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be2e34e",
   "metadata": {},
   "source": [
    "### Считаем триграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027e035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "trigram_counter = Counter()\n",
    "\n",
    "for sentence in data_no_stopwords:\n",
    "    for i in range(len(sentence) - 2):\n",
    "       \n",
    "        # Создаем триграмму и преобразуем в строку с разделение через подчеркивание\n",
    "        trigram = \"_\".join(sentence[i:i + 3])\n",
    "        # Увеличиваем счетчик для этой триграммы\n",
    "        trigram_counter[trigram] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c561e616",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(trigram_counter.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06556ff9",
   "metadata": {},
   "source": [
    "### С помощью nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfe3b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "# Словарь для подсчета триграмм\n",
    "trigram_counter_nltk = Counter()\n",
    "\n",
    "for sentence in data_no_stopwords:\n",
    "    # Генерируем триграммы и преобразуем их в строки, сразу подсчитываем их\n",
    "    trigram_counter_nltk.update(\"_\".join(ngram) for ngram in ngrams(sentence, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737f5620",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(trigram_counter_nltk.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64db520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Находим топ 30 самых популярных триграмм\n",
    "top_30_trigrams = trigram_counter.most_common(30)\n",
    "\n",
    "# Распаковываем данные\n",
    "trigrams, counts = zip(*top_30_trigrams)\n",
    "\n",
    "# Создаем построение\n",
    "plt.figure(figsize=(10, 8), dpi=180)\n",
    "plt.barh(trigrams, counts, color='skyblue')\n",
    "plt.xlabel('Частота')\n",
    "plt.ylabel('Триграмма')\n",
    "plt.title('Топ-30 самых популярных триграмм')\n",
    "plt.gca().invert_yaxis()  # перевернуть ось Y, чтобы самая частая триграмма была наверху\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29287cb",
   "metadata": {},
   "source": [
    "### t-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9177f5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def f_absolute(text, word):\n",
    "    return text.count(word)\n",
    "\n",
    "def f_nc(word, colocate1, colocate2):  \n",
    "    if word+'_'+colocate1+'_'+colocate2 in dict(sorted(trigram_counter.items(), key=lambda x:x[1], reverse=True)):\n",
    "        return dict(sorted(trigram_counter.items(), key=lambda x:x[1], reverse=True))[word+'_'+colocate1+'_'+colocate2]\n",
    "    else: return 0\n",
    "    \n",
    "def t_score(word,colocate1,colocate2,data_no_stopwords,n=3):\n",
    "    all_words = [item for sublist in data_no_stopwords for item in sublist]\n",
    "    N = len(all_words)\n",
    "    if f_nc(word, colocate1, colocate2)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (f_nc(word, colocate1, colocate2) - (f_absolute(all_words,word)*f_absolute(all_words,colocate1)*f_absolute(all_words,colocate2))/N**(n-1))/math.sqrt(f_nc(word, colocate1, colocate2))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4034217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_score_dic = {}\n",
    "for trigramm in sorted(trigram_counter.items(), key=lambda x:x[1], reverse=True)[:100]:\n",
    "    ts = t_score(trigramm[0].split(\"_\")[0], trigramm[0].split(\"_\")[1], trigramm[0].split(\"_\")[2] ,data_no_stopwords)\n",
    "    t_score_dic[trigramm[0]] = ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850a2116",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(t_score_dic.items(), key=lambda x:x[1], reverse=True)[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f20cff9",
   "metadata": {},
   "source": [
    "### with nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cb672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.collocations import *\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "\n",
    "text = [item for sublist in data_no_stopwords for item in sublist]\n",
    "finder_thr = TrigramCollocationFinder.from_words(text)\n",
    "\n",
    "# print(finder_thr.nbest(trigram_measures.student_t, 10))\n",
    "\n",
    "for i, t_score_val in enumerate(finder_thr.score_ngrams(trigram_measures.student_t)):\n",
    "    if i<30: print(t_score_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb89b1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
